(ml) greg@earth:~/Desktop/packt/B11764_Hands-On_GAN/Chapter 08-Break_Others/provided_code/cats_dogs$ python cats_dogs.py --model squeezenet1_1 --train_single True --data_dir ./cats-dogs-kaggle
Image loader backend: PIL
Logging to output/log.txt

PyTorch version: 1.3.1
CUDA version: 10.1.243

         Args         |    Type    |    Value
--------------------------------------------------
  model               |  str       |  squeezenet1_1
  cuda                |  bool      |  True
  train_single        |  bool      |  True
  train_ensemble      |  bool      |  True
  model_dir           |  str       |  ./models
  data_dir            |  str       |  ./cats-dogs-kaggle
  data_split          |  float     |  0.8
  cutout              |  bool      |  False
  cutout_length       |  int       |  64
  out_dir             |  str       |  output
  epochs              |  int       |  10
  batch_size          |  int       |  64
  lr                  |  float     |  0.01
  classes             |  int       |  2
  img_size            |  int       |  224
  channels            |  int       |  3
  log_interval        |  int       |  50
  pretrained_epoch    |  int       |  10
  seed                |  int       |  1
Loading data...

Transfer training model squeezenet1_1...

Using cache found in /home/greg/.cache/torch/hub/pytorch_vision_master
Downloading: "https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth" to /home/greg/.cache/torch/checkpoints/squeezenet1_1-f364aa15.pth
100%|██████████████████████████████████████| 4.74M/4.74M [00:00<00:00, 12.4MB/s]
Epoch 0, lr: 0.01
[0/25000]	loss: 0.7501	batch accuracy: 43.7500%
[3200/25000]	loss: 0.3464	batch accuracy: 84.3750%
[6400/25000]	loss: 0.1808	batch accuracy: 92.1875%
[9600/25000]	loss: 0.2790	batch accuracy: 87.5000%
[12800/25000]	loss: 0.1633	batch accuracy: 92.1875%
[16000/25000]	loss: 0.2230	batch accuracy: 90.6250%
[19200/25000]	loss: 0.2713	batch accuracy: 85.9375%
Eval loss: 0.2226, accuracy: 91.4400

Epoch 1, lr: 0.01
[0/25000]	loss: 0.2869	batch accuracy: 85.9375%
[3200/25000]	loss: 0.2542	batch accuracy: 89.0625%
[6400/25000]	loss: 0.2140	batch accuracy: 90.6250%
[9600/25000]	loss: 0.2763	batch accuracy: 87.5000%
[12800/25000]	loss: 0.0759	batch accuracy: 98.4375%
[16000/25000]	loss: 0.1922	batch accuracy: 90.6250%
[19200/25000]	loss: 0.1508	batch accuracy: 93.7500%
Eval loss: 0.2045, accuracy: 91.7600
Epoch 2, lr: 0.01
[0/25000]	loss: 0.1732	batch accuracy: 92.1875%
[3200/25000]	loss: 0.1602	batch accuracy: 90.6250%
[6400/25000]	loss: 0.1343	batch accuracy: 93.7500%
[9600/25000]	loss: 0.1603	batch accuracy: 92.1875%
[12800/25000]	loss: 0.1345	batch accuracy: 93.7500%
[16000/25000]	loss: 0.1770	batch accuracy: 89.0625%
[19200/25000]	loss: 0.1782	batch accuracy: 90.6250%
Eval loss: 0.1852, accuracy: 92.5000
Epoch 3, lr: 0.01
[0/25000]	loss: 0.1353	batch accuracy: 93.7500%
[3200/25000]	loss: 0.1059	batch accuracy: 96.8750%
[6400/25000]	loss: 0.1652	batch accuracy: 93.7500%
[9600/25000]	loss: 0.1713	batch accuracy: 90.6250%
[12800/25000]	loss: 0.2394	batch accuracy: 93.7500%
[16000/25000]	loss: 0.2225	batch accuracy: 89.0625%
[19200/25000]	loss: 0.2980	batch accuracy: 92.1875%
Eval loss: 0.1884, accuracy: 92.5800
Epoch 4, lr: 0.01
[0/25000]	loss: 0.0737	batch accuracy: 98.4375%
[3200/25000]	loss: 0.2101	batch accuracy: 92.1875%
[6400/25000]	loss: 0.0959	batch accuracy: 98.4375%
[9600/25000]	loss: 0.1244	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1571	batch accuracy: 93.7500%
[16000/25000]	loss: 0.0990	batch accuracy: 96.8750%
[19200/25000]	loss: 0.1733	batch accuracy: 95.3125%
Eval loss: 0.1794, accuracy: 93.0000
Epoch 5, lr: 0.001
[0/25000]	loss: 0.1775	batch accuracy: 92.1875%
[3200/25000]	loss: 0.1661	batch accuracy: 93.7500%
[6400/25000]	loss: 0.2263	batch accuracy: 92.1875%
[9600/25000]	loss: 0.1187	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1075	batch accuracy: 96.8750%
[16000/25000]	loss: 0.2038	batch accuracy: 87.5000%
[19200/25000]	loss: 0.3276	batch accuracy: 92.1875%
Eval loss: 0.1704, accuracy: 92.8400
Epoch 6, lr: 0.001
[0/25000]	loss: 0.0999	batch accuracy: 96.8750%
[3200/25000]	loss: 0.1106	batch accuracy: 95.3125%
[6400/25000]	loss: 0.1398	batch accuracy: 93.7500%
[9600/25000]	loss: 0.2209	batch accuracy: 89.0625%
[12800/25000]	loss: 0.0865	batch accuracy: 98.4375%
[16000/25000]	loss: 0.1010	batch accuracy: 93.7500%
[19200/25000]	loss: 0.1780	batch accuracy: 95.3125%
Eval loss: 0.1749, accuracy: 93.0000
Epoch 7, lr: 0.001
[0/25000]	loss: 0.2347	batch accuracy: 90.6250%
[3200/25000]	loss: 0.1020	batch accuracy: 95.3125%
[6400/25000]	loss: 0.2091	batch accuracy: 85.9375%
[9600/25000]	loss: 0.1718	batch accuracy: 92.1875%
[12800/25000]	loss: 0.1622	batch accuracy: 93.7500%
[16000/25000]	loss: 0.0933	batch accuracy: 95.3125%
[19200/25000]	loss: 0.1247	batch accuracy: 95.3125%
Eval loss: 0.1682, accuracy: 93.1200
Epoch 8, lr: 0.001
[0/25000]	loss: 0.0761	batch accuracy: 96.8750%
[3200/25000]	loss: 0.1480	batch accuracy: 90.6250%
[6400/25000]	loss: 0.1200	batch accuracy: 95.3125%
[9600/25000]	loss: 0.1699	batch accuracy: 93.7500%
[12800/25000]	loss: 0.0937	batch accuracy: 96.8750%
[16000/25000]	loss: 0.1507	batch accuracy: 90.6250%
[19200/25000]	loss: 0.0855	batch accuracy: 96.8750%
Eval loss: 0.1793, accuracy: 92.4600
Epoch 9, lr: 0.001
[0/25000]	loss: 0.2373	batch accuracy: 89.0625%
[3200/25000]	loss: 0.1312	batch accuracy: 93.7500%
[6400/25000]	loss: 0.1342	batch accuracy: 93.7500%
[9600/25000]	loss: 0.0820	batch accuracy: 98.4375%
[12800/25000]	loss: 0.1749	batch accuracy: 93.7500%
[16000/25000]	loss: 0.1335	batch accuracy: 93.7500%
[19200/25000]	loss: 0.2027	batch accuracy: 92.1875%
Eval loss: 0.1665, accuracy: 93.1400
Epoch 10, lr: 0.00010000000000000002
[0/25000]	loss: 0.1955	batch accuracy: 92.1875%
[3200/25000]	loss: 0.1211	batch accuracy: 95.3125%
[6400/25000]	loss: 0.1211	batch accuracy: 93.7500%
[9600/25000]	loss: 0.1112	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1538	batch accuracy: 92.1875%
[16000/25000]	loss: 0.0706	batch accuracy: 98.4375%
[19200/25000]	loss: 0.2843	batch accuracy: 87.5000%
Eval loss: 0.1708, accuracy: 92.9800
Epoch 11, lr: 0.00010000000000000002
[0/25000]	loss: 0.1504	batch accuracy: 92.1875%
[3200/25000]	loss: 0.1346	batch accuracy: 95.3125%
[6400/25000]	loss: 0.2310	batch accuracy: 92.1875%
[9600/25000]	loss: 0.0627	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1687	batch accuracy: 93.7500%
[16000/25000]	loss: 0.1727	batch accuracy: 89.0625%
[19200/25000]	loss: 0.1251	batch accuracy: 93.7500%
Eval loss: 0.1742, accuracy: 93.0600
Epoch 12, lr: 0.00010000000000000002
[0/25000]	loss: 0.1399	batch accuracy: 95.3125%
[3200/25000]	loss: 0.0950	batch accuracy: 96.8750%
[6400/25000]	loss: 0.1623	batch accuracy: 95.3125%
[9600/25000]	loss: 0.1689	batch accuracy: 92.1875%
[12800/25000]	loss: 0.1245	batch accuracy: 95.3125%
[16000/25000]	loss: 0.2298	batch accuracy: 92.1875%
[19200/25000]	loss: 0.1004	batch accuracy: 96.8750%
Eval loss: 0.1714, accuracy: 92.8800
Epoch 13, lr: 0.00010000000000000002
[0/25000]	loss: 0.0992	batch accuracy: 96.8750%
[3200/25000]	loss: 0.1293	batch accuracy: 92.1875%
[6400/25000]	loss: 0.0928	batch accuracy: 96.8750%
[9600/25000]	loss: 0.1009	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1083	batch accuracy: 93.7500%
[16000/25000]	loss: 0.2599	batch accuracy: 90.6250%
[19200/25000]	loss: 0.0811	batch accuracy: 96.8750%
Eval loss: 0.1707, accuracy: 93.1200
Epoch 14, lr: 0.00010000000000000002
[0/25000]	loss: 0.3153	batch accuracy: 89.0625%
[3200/25000]	loss: 0.0924	batch accuracy: 95.3125%
[6400/25000]	loss: 0.1515	batch accuracy: 96.8750%
[9600/25000]	loss: 0.2801	batch accuracy: 90.6250%
[12800/25000]	loss: 0.0625	batch accuracy: 96.8750%
[16000/25000]	loss: 0.1288	batch accuracy: 92.1875%
[19200/25000]	loss: 0.1953	batch accuracy: 90.6250%
Eval loss: 0.1698, accuracy: 92.9000
Epoch 15, lr: 1.0000000000000003e-05
[0/25000]	loss: 0.2634	batch accuracy: 90.6250%
[3200/25000]	loss: 0.1427	batch accuracy: 90.6250%
[6400/25000]	loss: 0.1669	batch accuracy: 90.6250%
[9600/25000]	loss: 0.1225	batch accuracy: 95.3125%
[12800/25000]	loss: 0.0942	batch accuracy: 98.4375%
[16000/25000]	loss: 0.3255	batch accuracy: 87.5000%
[19200/25000]	loss: 0.0910	batch accuracy: 95.3125%
Eval loss: 0.1698, accuracy: 93.0200
Epoch 16, lr: 1.0000000000000003e-05
[0/25000]	loss: 0.1498	batch accuracy: 93.7500%
[3200/25000]	loss: 0.4470	batch accuracy: 84.3750%
[6400/25000]	loss: 0.2073	batch accuracy: 95.3125%
[9600/25000]	loss: 0.1102	batch accuracy: 93.7500%
[12800/25000]	loss: 0.1954	batch accuracy: 92.1875%
[16000/25000]	loss: 0.0991	batch accuracy: 96.8750%
[19200/25000]	loss: 0.2039	batch accuracy: 90.6250%
Eval loss: 0.1734, accuracy: 92.8600
Epoch 17, lr: 1.0000000000000003e-05
[0/25000]	loss: 0.2197	batch accuracy: 90.6250%
[3200/25000]	loss: 0.3246	batch accuracy: 84.3750%
[6400/25000]	loss: 0.1260	batch accuracy: 95.3125%
[9600/25000]	loss: 0.1101	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1149	batch accuracy: 95.3125%
[16000/25000]	loss: 0.1788	batch accuracy: 93.7500%
[19200/25000]	loss: 0.1249	batch accuracy: 93.7500%
Eval loss: 0.1722, accuracy: 93.2200
Epoch 18, lr: 1.0000000000000003e-05
[0/25000]	loss: 0.1532	batch accuracy: 92.1875%
[3200/25000]	loss: 0.0918	batch accuracy: 96.8750%
[6400/25000]	loss: 0.1774	batch accuracy: 90.6250%
[9600/25000]	loss: 0.1056	batch accuracy: 96.8750%
[12800/25000]	loss: 0.1233	batch accuracy: 96.8750%
[16000/25000]	loss: 0.2399	batch accuracy: 89.0625%
[19200/25000]	loss: 0.1528	batch accuracy: 93.7500%
Eval loss: 0.1820, accuracy: 92.9400
Epoch 19, lr: 1.0000000000000003e-05
[0/25000]	loss: 0.2231	batch accuracy: 90.6250%
[3200/25000]	loss: 0.1126	batch accuracy: 93.7500%
[6400/25000]	loss: 0.1667	batch accuracy: 92.1875%
[9600/25000]	loss: 0.1775	batch accuracy: 93.7500%
[12800/25000]	loss: 0.1591	batch accuracy: 92.1875%
[16000/25000]	loss: 0.2134	batch accuracy: 90.6250%
[19200/25000]	loss: 0.1652	batch accuracy: 92.1875%
Eval loss: 0.1736, accuracy: 92.8800
Epoch 20, lr: 1.0000000000000002e-06
[0/25000]	loss: 0.0703	batch accuracy: 98.4375%
[3200/25000]	loss: 0.1278	batch accuracy: 92.1875%
[6400/25000]	loss: 0.1386	batch accuracy: 96.8750%
[9600/25000]	loss: 0.0620	batch accuracy: 98.4375%
[12800/25000]	loss: 0.0880	batch accuracy: 95.3125%
[16000/25000]	loss: 0.1766	batch accuracy: 93.7500%
[19200/25000]	loss: 0.1948	batch accuracy: 92.1875%
Eval loss: 0.1699, accuracy: 92.9600
Epoch 21, lr: 1.0000000000000002e-06
[0/25000]	loss: 0.1539	batch accuracy: 93.7500%
[3200/25000]	loss: 0.3414	batch accuracy: 82.8125%
[6400/25000]	loss: 0.1991	batch accuracy: 87.5000%
[9600/25000]	loss: 0.1464	batch accuracy: 95.3125%
[12800/25000]	loss: 0.1000	batch accuracy: 93.7500%
[16000/25000]	loss: 0.1413	batch accuracy: 95.3125%
[19200/25000]	loss: 0.1198	batch accuracy: 96.8750%
Eval loss: 0.1722, accuracy: 93.0200
Epoch 22, lr: 1.0000000000000002e-06
[0/25000]	loss: 0.1220	batch accuracy: 95.3125%
[3200/25000]	loss: 0.1325	batch accuracy: 93.7500%
[6400/25000]	loss: 0.2621	batch accuracy: 90.6250%
[9600/25000]	loss: 0.1636	batch accuracy: 93.7500%
[12800/25000]	loss: 0.1186	batch accuracy: 95.3125%
[16000/25000]	loss: 0.1766	batch accuracy: 90.6250%
[19200/25000]	loss: 0.1473	batch accuracy: 95.3125%
Eval loss: 0.1733, accuracy: 92.7800
Epoch 23, lr: 1.0000000000000002e-06
[0/25000]	loss: 0.0897	batch accuracy: 95.3125%
[3200/25000]	loss: 0.1357	batch accuracy: 95.3125%
[6400/25000]	loss: 0.1662	batch accuracy: 95.3125%
[9600/25000]	loss: 0.1896	batch accuracy: 93.7500%
[12800/25000]	loss: 0.1710	batch accuracy: 92.1875%
[16000/25000]	loss: 0.1839	batch accuracy: 90.6250%
[19200/25000]	loss: 0.0529	batch accuracy: 98.4375%
Eval loss: 0.1749, accuracy: 92.8000
Epoch 24, lr: 1.0000000000000002e-06
[0/25000]	loss: 0.2728	batch accuracy: 96.8750%
[3200/25000]	loss: 0.1659	batch accuracy: 95.3125%
[6400/25000]	loss: 0.2894	batch accuracy: 89.0625%
[9600/25000]	loss: 0.2120	batch accuracy: 90.6250%
[12800/25000]	loss: 0.1267	batch accuracy: 93.7500%
[16000/25000]	loss: 0.1682	batch accuracy: 93.7500%
[19200/25000]	loss: 0.1129	batch accuracy: 95.3125%
Eval loss: 0.1677, accuracy: 93.2000
Best test accuracy for model squeezenet1_1: 93.2200
Training GAN for adversarial attack...

epoch 1:
loss_D: 0.174, loss_G_fake: 0.653,             
loss_perturb: 22.516, loss_adv: 0.533, 


epoch 2:
loss_D: 0.028, loss_G_fake: 0.893,             
loss_perturb: 16.136, loss_adv: 0.344, 

epoch 3:
loss_D: 0.008, loss_G_fake: 0.942,             
loss_perturb: 14.535, loss_adv: 0.296, 

epoch 4:
loss_D: 0.001, loss_G_fake: 0.973,             
loss_perturb: 13.582, loss_adv: 0.250, 

epoch 5:
loss_D: 0.015, loss_G_fake: 0.948,             
loss_perturb: 13.022, loss_adv: 0.233, 

epoch 6:
loss_D: 0.001, loss_G_fake: 0.981,             
loss_perturb: 12.456, loss_adv: 0.216, 

epoch 7:
loss_D: 0.003, loss_G_fake: 0.977,             
loss_perturb: 12.277, loss_adv: 0.204, 

epoch 8:
loss_D: 0.007, loss_G_fake: 0.975,             
loss_perturb: 11.851, loss_adv: 0.194, 

epoch 9:
loss_D: 0.000, loss_G_fake: 0.989,             
loss_perturb: 11.512, loss_adv: 0.179, 

epoch 10:
loss_D: 0.004, loss_G_fake: 0.983,             
loss_perturb: 11.376, loss_adv: 0.180, 

Attacking ensemble model...

Eval loss: 0.6884, accuracy: 52.8800

